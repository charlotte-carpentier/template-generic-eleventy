# Robots.txt - Search Engine Crawling Rules
# Configure your site URL in src/_data/site.json

User-agent: *
Allow: /

# TODO: Update sitemap URL with your domain
# Replace example.com with your actual domain from site.json
Sitemap: https://example.com/sitemap.xml

# Block admin panel (Decap CMS)
Disallow: /admin/

# Allow assets (images, CSS, JS needed for SEO and rendering)
Allow: /assets/